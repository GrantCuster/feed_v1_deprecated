---
title: "The product possibilities for interpretability"
date: "Thu, 28 Sep 2017 03:00:00 GMT"
preview_image: "http://blog.fastforwardlabs.com/images/2017/09/refractor-local.gif"
external: "http://blog.fastforwardlabs.com/2017/09/28/the-product-possibilities-of-interpretability.html"
---

##### This post is part of a series highlighting the importance of interpretability. Previous posts include a [video conversation on interpretability](http://blog.fastforwardlabs.com/2017/09/11/interpretability-webinar.html), [a guide to using the LIME technique to predict whether couples will stay together](http://blog.fastforwardlabs.com/2017/09/01/LIME-for-couples.html), and a look at the [business rationale](http://blog.fastforwardlabs.com/2017/08/02/business-interpretability.html). In [our post on FairML](http://blog.fastforwardlabs.com/2017/03/09/fairml-auditing-black-box-predictive-models.html), we used interpretability techniques to identify discriminatory bias in algorithms.

As the use of machine learning algorithms increases, the need to understand
them grows as well. This is true at both a societal and a product level. As
algorithms enter into our workplaces and workflows, they can appear mysterious and
intimidating. Their predictions may be precise, but the utility of those
predictions is limited if we cannot understand how they were reached. Without
interpretability, even accurate algorithms are poor team playersâ€”technically
correct but uncommunicative.

